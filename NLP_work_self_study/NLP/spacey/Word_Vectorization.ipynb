{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b8c235",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f22c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967000ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecfd6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A word vector is a multi dimesional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c935433",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wiki_us.txt\",\"r\")as f:\n",
    "    text= f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5bc273a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of America (U.S.A. or USA), commonly known as the United States (U.S. or US) or America, is a country primarily located in North America.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp(text)\n",
    "sentence1=list(doc.sents)[0]\n",
    "print(sentence1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d45841e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'COUNTRY', 'NATION', 'nation', 'COUNTIRES', 'nations', 'member-states', 'worLd', 'World', 'world']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "your_word = \"Country\"\n",
    "\n",
    "ms = nlp.vocab.vectors.most_similar(\n",
    "    np.asarray([nlp.vocab.vectors[nlp.vocab.strings[your_word]]]), n=10)\n",
    "words = [nlp.vocab.strings[w] for w in ms[0][0]]\n",
    "distances = ms[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139f71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"I like salty fries and hamburgers\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ee248b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers <-> Fast food tastes very good. 0.732822189442892\n"
     ]
    }
   ],
   "source": [
    "print(doc1,\"<->\",doc2,doc1.similarity(doc2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecea7b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers <-> Empire State building is in newyork 0.42828225973125505\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(\"Empire State building is in newyork\")\n",
    "print(doc1,\"<->\",doc3,doc1.similarity(doc3))\n",
    "\n",
    "#spacy is going into it's word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b32a9ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy oranges <-> I enjoy apples 0.9445392991167937\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(\"I enjoy oranges\")\n",
    "doc5 = nlp(\"I enjoy apples\")\n",
    "print(doc4,\"<->\",doc5,doc4.similarity(doc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae0105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I enjoy oranges <-> I enjoy burgers. 0.8226324017443503\n"
     ]
    }
   ],
   "source": [
    "# the similarity is not dependent on the contextual words...\n",
    "#rather its dependent on the semantics of the words\n",
    "\n",
    "doc6 = nlp(\"I enjoy burgers.\") \n",
    "print(doc4,\"<->\",doc6,doc4.similarity(doc6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac93979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salty fries <-> hamburgers 0.7304624\n"
     ]
    }
   ],
   "source": [
    "french_fries = doc1[2:4]\n",
    "burgers= doc1[5]\n",
    "print(french_fries,\"<->\",burgers,french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7b92bd",
   "metadata": {},
   "source": [
    "# Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51b53d4",
   "metadata": {},
   "source": [
    "A pipeline is a very commmon expression in data science. \n",
    "A pipeline is a sequence of pipes or actors on data, that make alterations to the data or extract informarion from it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe11dbc",
   "metadata": {},
   "source": [
    "spacy pipeline for ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3539e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp2= spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69589763",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e948d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "s= requests.get(\"https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt\")\n",
    "soup = BeautifulSoup(s.content).text.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
    "nlp.max_length = 5278439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7999b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94139\n",
      "CPU times: user 6.62 s, sys: 60.5 ms, total: 6.68 s\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc = nlp(soup)\n",
    "print (len(list(doc.sents)))\n",
    "# this is our own pipeline model which only splits it into senctences \n",
    "#if the en_core_web_sm pipeline was used it would have taken 47 minutes to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fad7fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'English' object has no attribute 'analyze_pipes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-46d9d953568a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_pipes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#works with spacy 2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'English' object has no attribute 'analyze_pipes'"
     ]
    }
   ],
   "source": [
    "nlp2.analyze_pipes()\n",
    "#works with spacy 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69986226",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E003] Not a valid pipeline component. Expected callable, but got 'entity_ruler' (name: 'None').[E004] If you meant to add a built-in component, use `create_pipe`: `nlp.add_pipe(nlp.create_pipe('entity_ruler'))`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-46f1ab117055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mruler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"entity_ruler\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mruler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE004\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_component_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E003] Not a valid pipeline component. Expected callable, but got 'entity_ruler' (name: 'None').[E004] If you meant to add a built-in component, use `create_pipe`: `nlp.add_pipe(nlp.create_pipe('entity_ruler'))`"
     ]
    }
   ],
   "source": [
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed7c4e9",
   "metadata": {},
   "source": [
    "# Using Spacy's Entity Ruler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad984fa",
   "metadata": {},
   "source": [
    "#two ways to create custom spacy pipeline:-\n",
    "#Rules Based approach\n",
    "#Machine learning Based Approach\n",
    "\n",
    "Good example for when to use machine lerning and when to use reg ex or rules:\n",
    "\n",
    "when there are a finite number of forms say date....only finite possible outcomes\n",
    "\n",
    "Machine learning can be used for names cause names are different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57d3ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"West Chestertenfieldville was referenced in Mr. Deeds.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2bcc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc  = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c2930e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf5640",
   "metadata": {},
   "source": [
    "em_core_web_sm model is a ml model for ner , but even a very robust machine learning model would identify west chestertenfield as a person "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4769eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler = nlp.add_pipe(nlp.create_pipe(\"entity_ruler\"))\n",
    "#adds entity ruler to last pipe of en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d7e540e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'add_patterns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8be27c781225>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"GPE\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"pattern\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"West Chestertenfieldville\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mruler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'add_patterns'"
     ]
    }
   ],
   "source": [
    "patterns = [{\"label\":\"GPE\" , \"pattern\":\"West Chestertenfieldville\"}]\n",
    "ruler.add_patterns(nlp.create_patterns(patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81102d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from spacy.language import Language\n",
    "\n",
    "boundary = re.compile('^[0-9]$')\n",
    "\n",
    "@Language.component(\"component\")\n",
    "def custom_seg(doc):\n",
    "    prev = doc[0].text\n",
    "    length = len(doc)\n",
    "    for index, token in enumerate(doc):\n",
    "        if (token.text == '.' and boundary.match(prev) and index!=(length - 1)):\n",
    "            doc[index+1].sent_start = False\n",
    "        prev = token.text\n",
    "    return doc\n",
    "    \n",
    "nlp.add_pipe(\"component\", before='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536870f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
