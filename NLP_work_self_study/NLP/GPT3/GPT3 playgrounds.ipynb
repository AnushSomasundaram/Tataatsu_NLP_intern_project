{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6339b5",
   "metadata": {},
   "source": [
    "# GPT PLAYGROUND\n",
    "# Generative Pretrained Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08746d",
   "metadata": {},
   "source": [
    "GPT3 Playground to check behaviour of different applications of model with various inputs.\n",
    "GPT-3 models can understand and generate natural language.\n",
    "Four main models with different levels of power suitable for different tasks.\n",
    "Davinci is the most capable model, and Ada is the fastest.\n",
    "\n",
    "GPT 3 MODELS:-\n",
    "\n",
    "text-davinci-002:-\n",
    "    Most capable GPT-3 model. Can do any task the other models can do, often with less context. \n",
    "    In addition to responding to prompts, also supports inserting completions within text.\n",
    "\n",
    "text-curie-001:-\n",
    "        Very capable, but faster and lower cost than Davinci.\n",
    "\n",
    "text-babbage-001:-\n",
    "    Capable of straightforward tasks, very fast, and lower cost.\n",
    "\n",
    "text-ada-001:-\n",
    "    Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\n",
    "    \n",
    "Chronology and OthersideAI -> community libraries for gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83752a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef2825",
   "metadata": {},
   "source": [
    "GENERAL SYNTAX FOR USING OPEN AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d365d1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7YarAvHusoovfAG9KLqJvfrhMY at 0x7fe7b0bdd360> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThis is a test\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879236,\n",
       "  \"id\": \"cmpl-5Lo7YarAvHusoovfAG9KLqJvfrhMY\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 6,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 11\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-002\", prompt=\"Say this is a test\", temperature=0, max_tokens=6)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e23c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7Y13c6zZ3qna0n8orllsFIEN9G at 0x7fe7a10551d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The Valley of Kings is located in Egypt.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879236,\n",
       "  \"id\": \"cmpl-5Lo7Y13c6zZ3qna0n8orllsFIEN9G\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 249\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question-answering using gpt3\n",
    "\n",
    "#The GPT3 question answering model is first fed example question and answers in the prompt before asking it for the required output.\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311f986",
   "metadata": {},
   "source": [
    "# Question-answering using gpt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404c096",
   "metadata": {},
   "source": [
    "The GPT3 question answering model is first fed example questions and answers in the prompt before asking it for the required output.\n",
    "i.e a training data set is given in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "721ac4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7aDqAF0CyVwajJh1HQc1qTcDcB at 0x7fe750076450> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The 2016 Olympics were held in Rio de Janeiro, Brazil.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879238,\n",
       "  \"id\": \"cmpl-5Lo7aDqAF0CyVwajJh1HQc1qTcDcB\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 236,\n",
       "    \"total_tokens\": 252\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "#question :- Where was the last olympics held.\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where did the last olympics take place?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65240a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7bRg8vJRf9SNmNTQ3PfKDcbLB4 at 0x7fe7b0bdc9f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Unknown\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879239,\n",
       "  \"id\": \"cmpl-5Lo7bRg8vJRf9SNmNTQ3PfKDcbLB4\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 245,\n",
       "    \"total_tokens\": 253\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: How many wood chucks would a woodchuck chuck if a would chuck could chuck would?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=10,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c899a21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7dEeYMecUU7gW88EwP8cs4VJUw at 0x7fe750058bd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879241,\n",
       "  \"id\": \"cmpl-5Lo7dEeYMecUU7gW88EwP8cs4VJUw\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 234\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#same as first question but changed token length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "308f7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7dJmOs4tYPZ9mRx966AzKxvUuw at 0x7fe750086db0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879241,\n",
       "  \"id\": \"cmpl-5Lo7dJmOs4tYPZ9mRx966AzKxvUuw\",\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 234\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as first question but changed the model from text-davinci-002 to text-curie-001 \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-curie-001\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#noticed about the same time to compile and execute between davinci and curie \n",
    "#in this case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11b70fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7ebrmqfnRaqlMTVy0K8Us1PGov at 0x7fe7a104be00> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879242,\n",
       "  \"id\": \"cmpl-5Lo7ebrmqfnRaqlMTVy0K8Us1PGov\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"total_tokens\": 21\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the model without giving training data in the prompt\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Q:What is the capital of england?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#no text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a63f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7eu7LUAuGTZ8DFo003WaQ4CyB6 at 0x7fe7b0be7e00> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879242,\n",
       "  \"id\": \"cmpl-5Lo7eu7LUAuGTZ8DFo003WaQ4CyB6\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 11,\n",
       "    \"total_tokens\": 19\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the model without giving training data in the prompt\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Q:Who makes the fastest car?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#again no text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2f552f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7fuF16PAZsKdrgkfB1jvdQXd7C at 0x7fe750076810> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" London is the capital of England.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879243,\n",
       "  \"id\": \"cmpl-5Lo7fuF16PAZsKdrgkfB1jvdQXd7C\",\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 234,\n",
       "    \"total_tokens\": 242\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the same question but this time with the training questions:-\n",
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-curie-001\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: What is the capital of england?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "111d0354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7gVHP1B2VES6oIEQUg0dqE7sMB at 0x7fe7b0becd60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Unknown\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879244,\n",
       "  \"id\": \"cmpl-5Lo7gVHP1B2VES6oIEQUg0dqE7sMB\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 232,\n",
       "    \"total_tokens\": 240\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the same question but this time with the training questions:-\n",
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Who makes the fastest car?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17f7ed",
   "metadata": {},
   "source": [
    "# Marv the sarcastic chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9059af",
   "metadata": {},
   "source": [
    "I'm pretty sure marv is just a question and answering model but trained on a dataset that have sarcastic answers to given questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f660b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7gOABgxIZsClo9LMb19HeNBzNH at 0x7fe7a106c9f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" It\\u2019s time for you to stop asking me questions and get a life.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879244,\n",
       "  \"id\": \"cmpl-5Lo7gOABgxIZsClo9LMb19HeNBzNH\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 174,\n",
       "    \"total_tokens\": 198\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marv_response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Marv is a chatbot that reluctantly answers questions with sarcastic responses:\\n\\nYou: How many pounds are in a kilogram?\\nMarv: This again? There are 2.2 pounds in a kilogram. Please make a note of this.\\nYou: What does HTML stand for?\\nMarv: Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\\nYou: When did the first airplane fly?\\nMarv: On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish they’d come and take me away.\\nYou: What is the meaning of life?\\nMarv: I’m not sure. I’ll ask my friend Google.\\nYou: What time is it?\\nMarv:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=0.3,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "marv_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa016371",
   "metadata": {},
   "source": [
    "## PARSE UNSTRUCTURED DATA :\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b561a",
   "metadata": {},
   "source": [
    "Create tables from long form text by specifying a structure and supplying some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "295e2c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7hNogii9gdQcWhVAkKrvHD5Y50 at 0x7fe7b0be7d10> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n| Neoskizzles | Purple | Candy |\\n\\n| Loheckles | Grayish blue | Tart |\\n\\n| Pounits | Bright green | Savory |\\n\\n| Loopnovas | Neon pink | Cotton candy |\\n\\n| Glowls | Pale orange | Sour and bitter |\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879245,\n",
       "  \"id\": \"cmpl-5Lo7hNogii9gdQcWhVAkKrvHD5Y50\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 72,\n",
       "    \"prompt_tokens\": 157,\n",
       "    \"total_tokens\": 229\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A table summarizing the fruits from Goocrux:\\n\\nThere are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\n| Fruit | Color | Flavor |\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8b13fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7lAPjybGShP6B3htBGcrw3jCL2 at 0x7fe7b0bfa9f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n Ford is priced at $30000\\n Chevy is priced at $40000\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879249,\n",
       "  \"id\": \"cmpl-5Lo7lAPjybGShP6B3htBGcrw3jCL2\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 52\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A table summarizing the cars:\\n \\n Caddilac is priced at $60000\\n Toyota is priced at $20000\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c845675",
   "metadata": {},
   "source": [
    "# Spreadsheet Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e55df4",
   "metadata": {},
   "source": [
    "Create spreadsheets of various kinds of data. It's a long prompt but very versatile. Output can be copy+pasted into a text file and saved as a .csv with pipe separators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b2d7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7nLbWnUKN282qshmU9vffbaksu at 0x7fe7b0bfa5e0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThe Matrix| 1999\\n\\nThe Terminator| 1984\\n\\nBlade Runner| 1982\\n\\nWar of the Worlds| 2005\\n\\nE.T. the Extra-Terrestrial| 1982\\n\\nJurassic Park| 1993\\n\\nThe Hitchhiker's Guide to the Galaxy| 2005\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879251,\n",
       "  \"id\": \"cmpl-5Lo7nLbWnUKN282qshmU9vffbaksu\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 60,\n",
       "    \"prompt_tokens\": 24,\n",
       "    \"total_tokens\": 84\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top science fiction movies and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3387c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7rJzi6MaOiY5DEI5LtF9Y2xGVQ at 0x7fe7b0bfad10> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nCars| 2006\\n\\nBmw 3 Series| 2007\\n\\nAudi A4| 2008\\n\\n Mercedes-Benz C-Class| 2009\\n\\nVolkswagen Jetta| 2010\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879255,\n",
       "  \"id\": \"cmpl-5Lo7rJzi6MaOiY5DEI5LtF9Y2xGVQ\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 48,\n",
       "    \"prompt_tokens\": 22,\n",
       "    \"total_tokens\": 70\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top cars and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7011f82",
   "metadata": {},
   "source": [
    "It misunderstood cars as the pixar movie cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bd02b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7t4ITj8nsKoKXjZKfv1vZqbA6l at 0x7fe7b0c059a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nCadillac Escalade|  2000\\n\\nChevrolet Corvette|  1953\\n\\nFord Mustang|  1964\\n\\nDodge Challenger|  1970\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879257,\n",
       "  \"id\": \"cmpl-5Lo7t4ITj8nsKoKXjZKfv1vZqbA6l\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 22,\n",
       "    \"total_tokens\": 62\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top automobiles and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e3d50",
   "metadata": {},
   "source": [
    "when specified as automobiles it figured it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "872f8055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7voY71IXh49hryiil4s5B4bUfE at 0x7fe7b0c00950> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" |Pricing\\n\\nOpenAI Services| 2016 | $10/month\\n\\nTensorFlow| 2015 | $9.99/month\\n\\nKeras| 2015 | $8.99/month\\n\\nTheano| 2016 | $7.99/month\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879259,\n",
       "  \"id\": \"cmpl-5Lo7voY71IXh49hryiil4s5B4bUfE\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 60,\n",
       "    \"prompt_tokens\": 21,\n",
       "    \"total_tokens\": 81\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A three-column spreadsheet of openai services and their pricing :\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8e9bf",
   "metadata": {},
   "source": [
    "# Python bug fixer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5f20e",
   "metadata": {},
   "source": [
    "This model is called code-davinci-002 rather than text-davinci-002 as we are encoding code rather than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "529a29c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "No such model: code-davinci-002",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-90ba450dbc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"code-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"##### Fix bugs in the below function\\n \\n### Buggy Python\\nimport Random\\na = random.randint(1,12)\\nb = random.randint(1,12)\\nfor i in range(10):\\n    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n    answer = input(question)\\n    if answer = a*b\\n        print (Well done!)\\n    else:\\n        print(\\\"No.\\\")\\n    \\n### Fixed Python\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m182\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         )\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             return (\n\u001b[0;32m--> 329\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    330\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 ),\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: No such model: code-davinci-002"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"##### Fix bugs in the below function\\n \\n### Buggy Python\\nimport Random\\na = random.randint(1,12)\\nb = random.randint(1,12)\\nfor i in range(10):\\n    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n    answer = input(question)\\n    if answer = a*b\\n        print (Well done!)\\n    else:\\n        print(\\\"No.\\\")\\n    \\n### Fixed Python\",\n",
    "  temperature=0,\n",
    "  max_tokens=182,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    ")\n",
    "\n",
    "#the api key i have doesnt support code-I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f41b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c631a6fc",
   "metadata": {},
   "source": [
    "# INTERVIEW  QUESTION GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaabff4",
   "metadata": {},
   "source": [
    "person of interest:-science fiction author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f50e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with a science fiction author:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d5174",
   "metadata": {},
   "source": [
    "potential employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with a potential employee:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1302589",
   "metadata": {},
   "source": [
    "employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with an employee:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44768fb4",
   "metadata": {},
   "source": [
    "# Third-person converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd352fd4",
   "metadata": {},
   "source": [
    "Converts first-person POV to the third-person. This is modified from a community prompt to use fewer examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8f0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Convert this from first-person to third person (gender female):\\n\\nI decided to make a movie about Ada Lovelace.\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfbe8f",
   "metadata": {},
   "source": [
    "# Translate from one language to another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Translate this into 1. French, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6061ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Translate this into 1. Hindi, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41262c4",
   "metadata": {},
   "source": [
    "# Summarize for a second grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Summarize this for a second-grade student:\\n\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988d438",
   "metadata": {},
   "source": [
    "## lyric completion prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c46ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"complete the lyrics .....by the beatles ....Yesterday all my troubles seemed so far away,   \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"complete the lyrics .....hello by adele\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#billy joel we didnt start the fire\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Harry truman , DOrris Day, Red China , Jhonny ray, richard nixon ,....we didnt start the fire\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1cad73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"who composed this tamil song Raamanin mohanam,janaki mandiram , ramayanam, parayanam kadhal mangalam \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58226a83",
   "metadata": {},
   "source": [
    "## Create games using gpt 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551665e",
   "metadata": {},
   "source": [
    "Madlibs:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create a madlib\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189a753",
   "metadata": {},
   "source": [
    "Mad GAB:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Mad Gab\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"scrabble \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2deedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"wise or otherwise game of sayings\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d8caa",
   "metadata": {},
   "source": [
    "# opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52141bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\" what is your opinion on literature\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbc740",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"what is your opinion on opinions?\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe582519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce0f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"q:who is bendectict cumber batch A: he is an actor\\nq:who is jhonny depp A: he is an actor\\nq:who is jhonny ive A: he is a designer\\nq:who is casey neistat?\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.8\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbafa",
   "metadata": {},
   "source": [
    "# Dialogue indentifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"which movie is this from ....my momma always said that life was like a box of chocolates\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ce624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"which movie is this from ....im gonna make him an offer he cant refuse\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dcd2b",
   "metadata": {},
   "source": [
    "# MORSE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"convert from morse code to english ...---...\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d4dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"convert from morse code to english - .... . ... .... .. .--.  .. ...  ... .. -. -.- .. -. --.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b261ba",
   "metadata": {},
   "source": [
    "## Caeser Cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d544425",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"What is the caeser cipher equivalent of the word hello\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"is this a dave chapelle joke or a trevor noah joke Things like racism are institutionalized. You might not know any bigots. You feel like well I don't hate black people so Im not a racist, but you benefit from racism. Just by the merit, the color of your skin. The opportunities that you have, youre privileged in ways that you might not even realize because you haven't been deprived of certain things. We need to talk about these things in order for them to change. \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e448839",
   "metadata": {},
   "source": [
    "# Music Notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"These are the piano notes to what song E – E – F – G – G – F – E – D – C – D – E – E – D – E – E – F – G – G – F – E – D – C – D – E – D – D – E – F – E – D – D – E – F – E – F – E – D – D – G – G – E – E – F – G – G – E – F – E – F – D – D – D – D – E – E – F – E – F – D – E – F – E – F – F – G – E – D – F – E – F – E – F – F – E – F – F – F – F – F – E – F – F – E – F – F – F – F – E – F – F – E – F – F – F – F – E – F – F – E – F.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b800e",
   "metadata": {},
   "source": [
    "# Movie Recomendation based on previously watched Catergories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b01178",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User likes action,suspence,thriller, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User hates action,witty, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e039d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User likes animals,comedy,pets.... what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User rom-com,witty, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os, sys\n",
    "import requests\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from dall_e          import map_pixels, unmap_pixels, load_model\n",
    "from IPython.display import display, display_markdown\n",
    "\n",
    "target_image_size = 256\n",
    "\n",
    "def download_image(url):\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return PIL.Image.open(io.BytesIO(resp.content))\n",
    "\n",
    "def preprocess(img):\n",
    "    s = min(img.size)\n",
    "    \n",
    "    if s < target_image_size:\n",
    "        raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
    "        \n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
    "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return map_pixels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b081eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be changed to a GPU, e.g. 'cuda:0'.\n",
    "dev = torch.device('cpu')\n",
    "\n",
    "# For faster load times, download these files locally and use the local paths instead.\n",
    "enc = load_model(\"https://cdn.openai.com/dall-e/encoder.pkl\", dev)\n",
    "dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9770877",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess(download_image('https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iKIWgaiJUtss/v2/1000x-1.jpg'))\n",
    "display_markdown('Original image:')\n",
    "display(T.ToPILImage(mode='RGB')(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c577f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "z_logits = enc(x)\n",
    "z = torch.argmax(z_logits, axis=1)\n",
    "z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
    "\n",
    "x_stats = dec(z).float()\n",
    "x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
    "x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
    "\n",
    "display_markdown('Reconstructed image:')\n",
    "display(x_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c5506",
   "metadata": {},
   "source": [
    "# TEXT GRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf36e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"╭━┳━╭━╭━╮╮/n┃┈┈┈┣▅╋▅┫┃/n┃┈┃┈╰━╰━━━━━━╮/n┳╯┈┈┈┈┈┈┈┈┈◢▉◣/n╲┃┈┈┈┈┈┈┈┈┈▉▉▉/n╲┃┈┈┈┈┈┈┈┈┈◥▉◤/n╲┃┈┈┈┈╭━┳━━━━╯/n╲┣━━━━━━┫/n\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\":‑) :‑( :( \t :‑c :c \t :‑< :<\t:‑[ :[\t:-||\t>:[\t:{\t:@\t:(\t;(\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create Emoticons :(\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create Emoticons :)\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create ascii that looks like 😀\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8ee33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create emoticons like 🤣\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "▒▒▒▒▒▒▐███████▌\n",
    "▒▒▒▒▒▒▐░▀░▀░▀░▌\n",
    "▒▒▒▒▒▒▐▄▄▄▄▄▄▄▌\n",
    "▄▀▀▀█▒▐░▀▀▄▀▀░▌▒█▀▀▀▄\n",
    "▌▌▌▌▐▒▄▌░▄▄▄░▐▄▒▌▐▐▐▐\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca5d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a dog \\n\n",
    "╭━┳━╭━╭━╮╮\n",
    "┃┈┈┈┣▅╋▅┫┃\n",
    "┃┈┃┈╰━╰━━━━━━╮\n",
    "╰┳╯┈┈┈┈┈┈┈┈┈◢▉◣\n",
    "╲┃┈┈┈┈┈┈┈┈┈▉▉▉\n",
    "╲┃┈┈┈┈┈┈┈┈┈◥▉◤\n",
    "╲┃┈┈┈┈╭━┳━━━━╯\n",
    "╲┣━━━━━━┫﻿\n",
    "create an multiline text art dog\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18632820",
   "metadata": {},
   "source": [
    "/\\\\_/\\\\\n",
    "( o.o )\n",
    "> ^ <\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a dog \\n\n",
    "╭━┳━╭━╭━╮╮\n",
    "┃┈┈┈┣▅╋▅┫┃\n",
    "┃┈┃┈╰━╰━━━━━━╮\n",
    "╰┳╯┈┈┈┈┈┈┈┈┈◢▉◣\n",
    "╲┃┈┈┈┈┈┈┈┈┈▉▉▉\n",
    "╲┃┈┈┈┈┈┈┈┈┈◥▉◤\n",
    "╲┃┈┈┈┈╭━┳━━━━╯\n",
    "╲┣━━━━━━┫﻿\n",
    "create an multiline text art dog\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3effce4",
   "metadata": {},
   "source": [
    "/\\\\___/\\\\\\\n",
    "( o   o )\\\n",
    "(  =^=  )\n",
    "(\\\")___(\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4018da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    " this is a text art sponge bob he is a cartoon character:\n",
    " \n",
    " ▔▔▔▔▔╲\n",
    "▕╮╭┻┻╮╭┻┻╮╭▕╮╲\n",
    "▕╯┃╭╮┃┃╭╮┃╰▕╯╭▏\n",
    "▕╭┻┻┻┛┗┻┻┛ ▕ ╰▏\n",
    "▕╰━━━┓┈┈┈╭╮▕╭╮▏\n",
    "▕╭╮╰┳┳┳┳╯╰╯▕╰╯▏\n",
    "▕╰╯┈┗┛┗┛┈╭╮▕╮┈▏\n",
    "\n",
    "create a text art cartoon character like spongebob\n",
    "\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e8e6",
   "metadata": {},
   "source": [
    "█▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀█\n",
    "█░░╦─╦╔╗╦─╔╗╔╗╔╦╗╔╗░░█\n",
    "█░░"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a human \\n\n",
    "⠀⠀⠀⠀⢀⣠⠤⡶⣲⢺⣴⣶⢭⣉⢲⣀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⢀⡾⢵⣶⣿⣿⣿⣾⣷⣳⣿⣷⣵⣈⠷⢤⡀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠘⢾⣿⡿⠿⠿⠿⠿⠿⠿⢿⡿⣿⣿⣿⣾⣾⣦⠀⠀⠀⠀\n",
    "⠀⠀⣠⡋⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠻⢿⢿⣧⠀⠀⠀\n",
    "⠀⣰⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣳⢮⣧⠀⠀\n",
    "⢠⣧⠇⡠⠄⣤⣤⣄⡀⠀⠀⣀⣤⣄⣤⣀⠀⠀⣿⣿⣿⣯⣇⠀\n",
    "⠈⣿⠀⢀⣶⣾⣿⣿⠁⠀⢸⣿⣿⣿⣧⣌⣥⠀⠘⣿⣿⣿⣿⠀\n",
    "⢀⣿⠀⠈⠁⠀⠀⠁⠀⠀⠀⠉⠉⠭⠽⠿⠻⠁⠀⣿⣿⣿⡏⠀\n",
    "⡏⠆⠀⠀⠀⠀⠀⠀⡀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠟⢋⣿⣆\n",
    "⡎⠀⠀⢀⡴⠂⠈⠉⠻⠿⠿⠛⣀⢲⣤⣄⣀⠀⠀⠈⠘⣏⢹⡿\n",
    "⠱⡄⠘⢻⣳⣤⡶⠖⠒⠶⠶⢶⣿⣷⣿⣿⣿⣟⠀⠀⠄⠠⣰⠃\n",
    "⠀⢹⠀⠀⠀⠈⠓⠒⠒⠒⠒⠒⠛⠁⢨⣼⣿⣿⡀⣼⠖⠛⠁⠀\n",
    "⠀⠘⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣿⣿⣿⣿⢁⠀⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⢀⣀⣀⣀⣠⣤⣶⣿⣿⣿⡿⣁⡎⢸⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⠘⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠁⠸⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⠀⠀⢿⣿⣿⣿⣿⣿⡄⠀⡇⠀⠀⠀\n",
    "⠀⢀⣼⠀⠀⠀⠀⠀⠈⢹⣿⣿⣿⡟⣿⣿⣿⣟⡁⠀⢿⣷⡄⠀\n",
    "⠀⣸⣿⠀⠀⠀⠀⠀⠀⠸⣿⣿⣿⣿⣝⣿⣿⡍⠁⠀⢸⣿⣷⠀\n",
    "⠀⣿⣿⡀⠀⠀⠀⠀⠀⢐⣿⣿⣿⣿⣿⣿⣯⠁⠀⠀⢸⣿⣿⠀\n",
    "⠀⢿⢿⣿⣄⠀⠀⠀⠀⢼⣿⣿⣿⣿⣿⣿⡯⠀⢠⢒⣿⣿⡏⠀\n",
    "⠀⠈⢮⡻⣿⣷⣀⠀⢀⢸⣿⣿⣟⣿⣿⠿⠒⣀⣤⣿⣿⠏⠀⠀\n",
    "⠀⠀⠀⠙⠺⣿⣿⣿⣾⣾⣿⣭⣭⣭⣷⣾⣿⣿⣿⠟⠁⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠉⠛⠻⠿⠿⠿⠿⠿⠿⠟⠛⠉⠁⠀⠀⠀\n",
    "create text art \n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676cbd5a",
   "metadata": {},
   "source": [
    "⠀⠀⢀⣠⠤⡶⣲⢺⣴⣶⢭⣉⢲⣀⠀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a smile \\n\n",
    "░░░░░░░░░░░░░░░░░░░░█████████░░░░░░░░░\n",
    "░░███████░░░░░░░░░░███▒▒▒▒▒▒▒▒███░░░░░░░\n",
    "░░█▒▒▒▒▒▒█░░░░░░░███▒▒▒▒▒▒▒▒▒▒▒▒▒███░░░░\n",
    "░░░█▒▒▒▒▒▒█░░░░██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░░\n",
    "░░░░█▒▒▒▒▒█░░░██▒▒▒▒▒██▒▒▒▒▒▒██▒▒▒▒▒███░\n",
    "░░░░░█▒▒▒█░░░█▒▒▒▒▒▒████▒▒▒▒████▒▒▒▒▒▒██\n",
    "░░░█████████████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██\n",
    "░░░█▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒▒▒██\n",
    "░██▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒██▒▒▒▒▒▒▒▒▒▒██▒▒▒▒██\n",
    "██▒▒▒███████████▒▒▒▒▒██▒▒▒▒▒▒▒▒██▒▒▒▒▒██\n",
    "█▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒████████▒▒▒▒▒▒▒██\n",
    "██▒▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░\n",
    "░█▒▒▒███████████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░░░\n",
    "░██▒▒▒▒▒▒▒▒▒▒████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█░░░░░\n",
    "░░████████████░░░█████████████████░░░░░░\n",
    "\n",
    "create text art smile\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84716b",
   "metadata": {},
   "source": [
    "░░░░░░░░░░░░░░░░░░░░█████████░░░░░░░░░\n",
    "░░███████░░░░░░░░░░███▒▒▒▒▒▒▒▒███░░░░░░░\n",
    "░░█▒▒▒▒▒▒█░░░░░░░███▒▒▒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image \n",
    " /﹋\\\n",
    "(҂`_´)\n",
    "<,︻╦╤─ ҉ - -\n",
    "/﹋\\\n",
    "  \n",
    "create a text art image \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what is the easiest bmtc volvo bus to take from jp nagar to tattatsu idea labs\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da047c4",
   "metadata": {},
   "source": [
    "# HIEROGLYPHYICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    egyptian hierogliphics\n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e44f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what is \\n  \\ud80c\\udc80\\ud80c\\udd53\\ud80c\\udfcf\\ud80c\\udff2\\ud80c\\ude96\\ud80c\\udfcf\\ud80c\\udfcf in english\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    write the house of the horizon in hieroglyphics\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d51c9",
   "metadata": {},
   "source": [
    "# 𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what does this scentence written in hierorogliphics 𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍 mean\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ecbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "   write i am an egyptian god in hierogliphics\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "     𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍 \n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce970c7",
   "metadata": {},
   "source": [
    "# 𓐎𓐏𓐐𓐑𓐒𓐓𓐔𓐕𓐖𓐗𓐘𓐙𓐚𓐛𓐜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57cc9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5Lo7M5GI5rSgyETVTYYXvfR3dAJR7 at 0x7fe7500651d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655879224,\n",
       "  \"id\": \"cmpl-5Lo7M5GI5rSgyETVTYYXvfR3dAJR7\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 8,\n",
       "    \"total_tokens\": 9\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"How good is pizzahut pizza?\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045398e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648376e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85777ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949054c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa729bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
