{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6339b5",
   "metadata": {},
   "source": [
    "# GPT PLAYGROUND\n",
    "# Generative Pretrained Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08746d",
   "metadata": {},
   "source": [
    "GPT3 Playground to check behaviour of different applications of model with various inputs.\n",
    "GPT-3 models can understand and generate natural language.\n",
    "Four main models with different levels of power suitable for different tasks.\n",
    "Davinci is the most capable model, and Ada is the fastest.\n",
    "\n",
    "GPT 3 MODELS:-\n",
    "\n",
    "text-davinci-002:-\n",
    "    Most capable GPT-3 model. Can do any task the other models can do, often with less context. \n",
    "    In addition to responding to prompts, also supports inserting completions within text.\n",
    "\n",
    "text-curie-001:-\n",
    "        Very capable, but faster and lower cost than Davinci.\n",
    "\n",
    "text-babbage-001:-\n",
    "    Capable of straightforward tasks, very fast, and lower cost.\n",
    "\n",
    "text-ada-001:-\n",
    "    Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.\n",
    "    \n",
    "Chronology and OthersideAI -> community libraries for gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83752a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef2825",
   "metadata": {},
   "source": [
    "GENERAL SYNTAX FOR USING OPEN AI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d365d1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIGe5jz54CwwRlFGKm1I0cL6e6V at 0x7f8a78978ea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThis is a test\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256612,\n",
       "  \"id\": \"cmpl-5NOIGe5jz54CwwRlFGKm1I0cL6e6V\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 6,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 11\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(model=\"text-davinci-002\", prompt=\"Say this is a test\", temperature=0, max_tokens=6)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e23c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIH9Gw4JO1qKQNeXuNQSxGcMT0s at 0x7f8a78978220> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The Valley of Kings is located in Egypt.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256613,\n",
       "  \"id\": \"cmpl-5NOIH9Gw4JO1qKQNeXuNQSxGcMT0s\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 249\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question-answering using gpt3\n",
    "\n",
    "#The GPT3 question answering model is first fed example question and answers in the prompt before asking it for the required output.\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9311f986",
   "metadata": {},
   "source": [
    "# Question-answering using gpt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404c096",
   "metadata": {},
   "source": [
    "The GPT3 question answering model is first fed example questions and answers in the prompt before asking it for the required output.\n",
    "i.e a training data set is given in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721ac4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIJllmD3a5CpN8xD9knBIPHeKMO at 0x7f8a9824a9a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The 2016 Olympics were held in Rio de Janeiro, Brazil.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256615,\n",
       "  \"id\": \"cmpl-5NOIJllmD3a5CpN8xD9knBIPHeKMO\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 236,\n",
       "    \"total_tokens\": 252\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "#question :- Where was the last olympics held.\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where did the last olympics take place?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65240a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIKW5I3QUa8pWFAdsREkxh5fp4P at 0x7f8a789a4cc0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Unknown\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256616,\n",
       "  \"id\": \"cmpl-5NOIKW5I3QUa8pWFAdsREkxh5fp4P\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 245,\n",
       "    \"total_tokens\": 253\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: How many wood chucks would a woodchuck chuck if a would chuck could chuck would?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=10,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c899a21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOILDx5bvfoWpzQfKiZICwcnRk6N at 0x7f8a78612d60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256617,\n",
       "  \"id\": \"cmpl-5NOILDx5bvfoWpzQfKiZICwcnRk6N\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 234\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#same as first question but changed token length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308f7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOILjJfVFzwW3bQaUASuyA2VomPA at 0x7f8a6806c4f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" The\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256617,\n",
       "  \"id\": \"cmpl-5NOILjJfVFzwW3bQaUASuyA2VomPA\",\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 234\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as first question but changed the model from text-davinci-002 to text-curie-001 \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-curie-001\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Where is the Valley of Kings?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#noticed about the same time to compile and execute between davinci and curie \n",
    "#in this case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b70fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIMMMy1T9zW8W4WWMtjtBBGA7Jh at 0x7f8a68072f90> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256618,\n",
       "  \"id\": \"cmpl-5NOIMMMy1T9zW8W4WWMtjtBBGA7Jh\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"total_tokens\": 21\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the model without giving training data in the prompt\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Q:What is the capital of england?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#no text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a63f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOINedX1UpyyPilYhveOq4yruAmw at 0x7f8a68072d60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256619,\n",
       "  \"id\": \"cmpl-5NOINedX1UpyyPilYhveOq4yruAmw\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 11,\n",
       "    \"total_tokens\": 19\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the model without giving training data in the prompt\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Q:Who makes the fastest car?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response\n",
    "\n",
    "#the required response can be obtained from the text section of the json\n",
    "#again no text output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2f552f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIOZuGRSM5MogwIAZqfBfM56bDN at 0x7f8a6806ca90> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" London is the capital of England.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256620,\n",
       "  \"id\": \"cmpl-5NOIOZuGRSM5MogwIAZqfBfM56bDN\",\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 234,\n",
       "    \"total_tokens\": 242\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the same question but this time with the training questions:-\n",
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-curie-001\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: What is the capital of england?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "111d0354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIOQnCZjUaBrZJvxM6gXwP6zBOj at 0x7f8a680759f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Unknown\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256620,\n",
       "  \"id\": \"cmpl-5NOIOQnCZjUaBrZJvxM6gXwP6zBOj\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 232,\n",
       "    \"total_tokens\": 240\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying the same question but this time with the training questions:-\n",
    "#question-answering using gpt3\n",
    "\n",
    "#How many would chucks would a woodchuck chuck if a wood chuck could chuck would? \n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"I am a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer. If you ask me a question that is nonsense, trickery, or has no clear answer, I will respond with \\\"Unknown\\\".\\n\\nQ: What is human life expectancy in the United States?\\nA: Human life expectancy in the United States is 78 years.\\n\\nQ: Who was president of the United States in 1955?\\nA: Dwight D. Eisenhower was president of the United States in 1955.\\n\\nQ: Which party did he belong to?\\nA: He belonged to the Republican Party.\\n\\nQ: What is the square root of banana?\\nA: Unknown\\n\\nQ: How does a telescope work?\\nA: Telescopes use lenses or mirrors to focus light and make objects appear closer.\\n\\nQ: Where were the 1992 Olympics held?\\nA: The 1992 Olympics were held in Barcelona, Spain.\\n\\nQ: How many squigs are in a bonk?\\nA: Unknown\\n\\nQ: Who makes the fastest car?\\nA:\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be17f7ed",
   "metadata": {},
   "source": [
    "# Marv the sarcastic chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9059af",
   "metadata": {},
   "source": [
    "I'm pretty sure marv is just a question and answering model but trained on a dataset that have sarcastic answers to given questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f660b24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIPjUXogLDBrIdd9fF6DLE28KLq at 0x7f8a680795e0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" It\\u2019s time for you to stop asking me questions and get a life.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256621,\n",
       "  \"id\": \"cmpl-5NOIPjUXogLDBrIdd9fF6DLE28KLq\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 174,\n",
       "    \"total_tokens\": 198\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marv_response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Marv is a chatbot that reluctantly answers questions with sarcastic responses:\\n\\nYou: How many pounds are in a kilogram?\\nMarv: This again? There are 2.2 pounds in a kilogram. Please make a note of this.\\nYou: What does HTML stand for?\\nMarv: Was Google too busy? Hypertext Markup Language. The T is for try to ask better questions in the future.\\nYou: When did the first airplane fly?\\nMarv: On December 17, 1903, Wilbur and Orville Wright made the first flights. I wish they’d come and take me away.\\nYou: What is the meaning of life?\\nMarv: I’m not sure. I’ll ask my friend Google.\\nYou: What time is it?\\nMarv:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=0.3,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "marv_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa016371",
   "metadata": {},
   "source": [
    "## PARSE UNSTRUCTURED DATA :\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b561a",
   "metadata": {},
   "source": [
    "Create tables from long form text by specifying a structure and supplying some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295e2c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIRHZRNDDw9SxeuDacYcasuW6V3 at 0x7f8a68075950> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n| Neoskizzles | Purple | Candy |\\n\\n| Loheckles | Grayish blue | Tart |\\n\\n| Pounits | Bright green | Savory |\\n\\n| Loopnovas | Neon pink | Cotton candy |\\n\\n| Glowls | Pale orange | Sour and bitter |\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256623,\n",
       "  \"id\": \"cmpl-5NOIRHZRNDDw9SxeuDacYcasuW6V3\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 72,\n",
       "    \"prompt_tokens\": 157,\n",
       "    \"total_tokens\": 229\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A table summarizing the fruits from Goocrux:\\n\\nThere are many fruits that were found on the recently discovered planet Goocrux. There are neoskizzles that grow there, which are purple and taste like candy. There are also loheckles, which are a grayish blue fruit and are very tart, a little bit like a lemon. Pounits are a bright green color and are more savory than sweet. There are also plenty of loopnovas which are a neon pink flavor and taste like cotton candy. Finally, there are fruits called glowls, which have a very sour and bitter taste which is acidic and caustic, and a pale orange tinge to them.\\n\\n| Fruit | Color | Flavor |\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b13fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIViOVt5Si2ubbTdflgCE1CyHGN at 0x7f8a68079ef0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n Ford is priced at $30000\\n Chevy is priced at $40000\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256627,\n",
       "  \"id\": \"cmpl-5NOIViOVt5Si2ubbTdflgCE1CyHGN\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 52\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A table summarizing the cars:\\n \\n Caddilac is priced at $60000\\n Toyota is priced at $20000\",\n",
    "  temperature=0,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c845675",
   "metadata": {},
   "source": [
    "# Spreadsheet Creator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e55df4",
   "metadata": {},
   "source": [
    "Create spreadsheets of various kinds of data. It's a long prompt but very versatile. Output can be copy+pasted into a text file and saved as a .csv with pipe separators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2d7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIXMSKEAWILv9SFQ3wiJbzkddhV at 0x7f8a68082450> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. The Matrix| 1999\\n\\n2. The Terminator| 1984\\n\\n3. Blade Runner| 1982\\n\\n4. War of the Worlds| 2005\\n\\n5. E.T. the Extra-Terrestrial| 1982\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256629,\n",
       "  \"id\": \"cmpl-5NOIXMSKEAWILv9SFQ3wiJbzkddhV\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 56,\n",
       "    \"prompt_tokens\": 24,\n",
       "    \"total_tokens\": 80\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top science fiction movies and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3387c1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIaErtPlhhryCB0xYS7jPF4pQMG at 0x7f8a68082ea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nCars|  2006\\n\\nToy Story 3|  2010\\n\\nThe Dark Knight Rises|  2012\\n\\nThe Hunger Games|  2012\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256632,\n",
       "  \"id\": \"cmpl-5NOIaErtPlhhryCB0xYS7jPF4pQMG\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 22,\n",
       "    \"total_tokens\": 62\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top cars and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7011f82",
   "metadata": {},
   "source": [
    "It misunderstood cars as the pixar movie cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd02b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIcIxAE1wwuG9oncbRXnCX8Bvbh at 0x7f8a68082c70> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nCadillac Eldorado|  1953\\n\\nChevrolet Corvette|  1953\\n\\nFord Thunderbird|  1955\\n\\nMercedes-Benz 300 SL|  1954\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256634,\n",
       "  \"id\": \"cmpl-5NOIcIxAE1wwuG9oncbRXnCX8Bvbh\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 22,\n",
       "    \"total_tokens\": 62\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A two-column spreadsheet of top automobiles and the year of release:\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5e3d50",
   "metadata": {},
   "source": [
    "when specified as automobiles it figured it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872f8055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIfT3gLqsti2y6ZapTwF2AD7lTo at 0x7f8a68087130> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" | Pricing\\n\\nService 1 | 2014 | $10/month\\n\\nService 2 | 2015 | $20/month\\n\\nService 3 | 2016 | $30/month\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256637,\n",
       "  \"id\": \"cmpl-5NOIfT3gLqsti2y6ZapTwF2AD7lTo\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 21,\n",
       "    \"total_tokens\": 61\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"A three-column spreadsheet of openai services and their pricing :\\n\\nTitle|  Year of release\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8e9bf",
   "metadata": {},
   "source": [
    "# Python bug fixer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5f20e",
   "metadata": {},
   "source": [
    "This model is called code-davinci-002 rather than text-davinci-002 as we are encoding code rather than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "529a29c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "That model does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-90ba450dbc01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"code-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"##### Fix bugs in the below function\\n \\n### Buggy Python\\nimport Random\\na = random.randint(1,12)\\nb = random.randint(1,12)\\nfor i in range(10):\\n    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n    answer = input(question)\\n    if answer = a*b\\n        print (Well done!)\\n    else:\\n        print(\\\"No.\\\")\\n    \\n### Fixed Python\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m182\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         )\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             return (\n\u001b[0;32m--> 329\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    330\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 ),\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    363\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: That model does not exist"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"code-davinci-002\",\n",
    "  prompt=\"##### Fix bugs in the below function\\n \\n### Buggy Python\\nimport Random\\na = random.randint(1,12)\\nb = random.randint(1,12)\\nfor i in range(10):\\n    question = \\\"What is \\\"+a+\\\" x \\\"+b+\\\"? \\\"\\n    answer = input(question)\\n    if answer = a*b\\n        print (Well done!)\\n    else:\\n        print(\\\"No.\\\")\\n    \\n### Fixed Python\",\n",
    "  temperature=0,\n",
    "  max_tokens=182,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"###\"]\n",
    ")\n",
    "\n",
    "#the api key i have doesnt support code-I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f41b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c631a6fc",
   "metadata": {},
   "source": [
    "# INTERVIEW  QUESTION GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaabff4",
   "metadata": {},
   "source": [
    "person of interest:-science fiction author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6f50e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIpGQXtgad2VnAdm9o62oqHn9yq at 0x7f8a68087630> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. What inspired you to write science fiction?\\n\\n2. What themes and settings are common in science fiction?\\n\\n3. How did you choose the story you wanted to tell, and what were some of the challenges you faced along the way?\\n\\n4. What are some of the unique elements that make science fiction stand out from other genres?\\n\\n5. What do you believe sets science fiction apart from other genres?\\n\\n6. How does science fiction differ from fantasy, and why is it such a popular genre?\\n\\n7. How do you ensure that your stories are accessible to a wide audience, and how do you ensure that they still maintain the essence of science fiction?\\n\\n8. Are\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256647,\n",
       "  \"id\": \"cmpl-5NOIpGQXtgad2VnAdm9o62oqHn9yq\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 150,\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"total_tokens\": 165\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with a science fiction author:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d5174",
   "metadata": {},
   "source": [
    "potential employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab31e4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIuLVRNWXlHSBtGwA6t2VKVrUBi at 0x7f8a680829f0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. What are your qualifications for the job?\\n2. What are your strengths and weaknesses?\\n3. Why do you want to work for us?\\n4. What are your career aspirations?\\n5. What can you do for us that other candidates can't?\\n6. What are your availability?\\n7. What are your salary expectations?\\n8. Do you have any questions for us?\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256652,\n",
       "  \"id\": \"cmpl-5NOIuLVRNWXlHSBtGwA6t2VKVrUBi\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 88,\n",
       "    \"prompt_tokens\": 14,\n",
       "    \"total_tokens\": 102\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with a potential employee:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1302589",
   "metadata": {},
   "source": [
    "employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed6d0486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOIyDonRtmekm1SwpNMYmgfukECD at 0x7f8a68075450> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n1. What are your primary job responsibilities?\\n2. What is your job title?\\n3. How long have you been with the company?\\n4. What is your educational background?\\n5. What are your career aspirations?\\n6. What do you enjoy most about your job?\\n7. What do you find most challenging about your job?\\n8. Can you share a recent project you\\u2019ve worked on that you\\u2019re particularly proud of?\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256656,\n",
       "  \"id\": \"cmpl-5NOIyDonRtmekm1SwpNMYmgfukECD\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 104,\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"total_tokens\": 117\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create a list of 8 questions for my interview with an employee:\",\n",
    "  temperature=0.5,\n",
    "  max_tokens=150,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44768fb4",
   "metadata": {},
   "source": [
    "# Third-person converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd352fd4",
   "metadata": {},
   "source": [
    "Converts first-person POV to the third-person. This is modified from a community prompt to use fewer examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e8f0a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJ3G53bRhB7fvl2xG4DgmRVZI9a at 0x7f8a789da1d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nShe decided to make a movie about Ada Lovelace.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256661,\n",
       "  \"id\": \"cmpl-5NOJ3G53bRhB7fvl2xG4DgmRVZI9a\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 44\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Convert this from first-person to third person (gender female):\\n\\nI decided to make a movie about Ada Lovelace.\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfbe8f",
   "metadata": {},
   "source": [
    "# Translate from one language to another "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c20e9f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJ4Fv7mXz8New0h8tcrszUb8RY2 at 0x7f8a789da0e0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Quels sont les chambres que vous avez disponibles?\\n2. \\u00bfQu\\u00e9 habitaciones tiene disponibles?\\n3. \\u3042\\u306a\\u305f\\u306f\\u3069\\u3093\\u306a\\u90e8\\u5c4b\\u3092\\u7528\\u610f\\u3057\\u3066\\u3044\\u307e\\u3059\\u304b\\uff1f\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256662,\n",
       "  \"id\": \"cmpl-5NOJ4Fv7mXz8New0h8tcrszUb8RY2\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 72,\n",
       "    \"prompt_tokens\": 29,\n",
       "    \"total_tokens\": 101\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Translate this into 1. French, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e6061ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJ7PUnwRrBSsIZsb1qvfUqEnCAe at 0x7f8a789daf90> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" \\u0906\\u092a\\u0915\\u0947 \\u092a\\u093e\\u0938 \\u0915\\u094d\\u092f\\u093e \\u0915\\u094d\\u0930\\u092e\\u093f\\u0915 \\u0915\\u092e\\u0930\\u0947 \\u0939\\u0948\\u0902?\\n2. \\u00bfQu\\u00e9 habitaciones tiene disponibles?\\n3. \\u3069\\u3093\\u306a\\u90e8\\u5c4b\\u304c\\u3042\\u308a\\u307e\\u3059\\u304b\\uff1f\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256665,\n",
       "  \"id\": \"cmpl-5NOJ7PUnwRrBSsIZsb1qvfUqEnCAe\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 88,\n",
       "    \"prompt_tokens\": 29,\n",
       "    \"total_tokens\": 117\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Translate this into 1. Hindi, 2. Spanish and 3. Japanese:\\n\\nWhat rooms do you have available?\\n\\n1.\",\n",
    "  temperature=0.3,\n",
    "  max_tokens=100,\n",
    "  top_p=1.0,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41262c4",
   "metadata": {},
   "source": [
    "# Summarize for a second grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57f43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9f13c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJB6Zto5EPoG7ynjjFPGT9etyyl at 0x7f8a789e7e00> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nJupiter is the fifth planet from the Sun and it is very large. It is much bigger than all the other planets in the Solar System combined. People have known about Jupiter for a very long time because it is very bright in the night sky.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256669,\n",
       "  \"id\": \"cmpl-5NOJB6Zto5EPoG7ynjjFPGT9etyyl\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 56,\n",
       "    \"prompt_tokens\": 151,\n",
       "    \"total_tokens\": 207\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Summarize this for a second-grade student:\\n\\nJupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c988d438",
   "metadata": {},
   "source": [
    "## lyric completion prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8c46ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJEGb9iGCA7MItG8CN4qJbu7N8E at 0x7f8a789da9a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nNow it looks as though they're here to stay,\\n\\nOh, I believe in yesterday.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256672,\n",
       "  \"id\": \"cmpl-5NOJEGb9iGCA7MItG8CN4qJbu7N8E\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 20,\n",
       "    \"total_tokens\": 44\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"complete the lyrics .....by the beatles ....Yesterday all my troubles seemed so far away,   \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2e6ed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJGLrpZiVbD8ICZuxo8JRs5RoJE at 0x7f8a88e78590> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nHello, can you hear me?\\nI am in California dreaming about who we used to be\\nWhen we were younger and free\\nI've forgotten how it felt before the world fell at our feet\\nThere's such a difference between us\\nAnd a million miles\\nHello from the other side\\nI must\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256674,\n",
       "  \"id\": \"cmpl-5NOJGLrpZiVbD8ICZuxo8JRs5RoJE\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 9,\n",
       "    \"total_tokens\": 73\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"complete the lyrics .....hello by adele\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03b6dcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJJtcmPtFw9c1lkzCgEOhiqfZIJ at 0x7f8a6808e310> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nIt was always burning\\n\\nSince the world's been turning\\n\\nWe didn't start the fire\\n\\nNo we didn't light it\\n\\nBut we tried to fight it\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256677,\n",
       "  \"id\": \"cmpl-5NOJJtcmPtFw9c1lkzCgEOhiqfZIJ\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 68\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#billy joel we didnt start the fire\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Harry truman , DOrris Day, Red China , Jhonny ray, richard nixon ,....we didnt start the fire\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db1cad73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJL0pwIXi26u84O3mP5RRecOOsS at 0x7f8a789da360> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThe song was composed by Ilaiyaraaja.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256679,\n",
       "  \"id\": \"cmpl-5NOJL0pwIXi26u84O3mP5RRecOOsS\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 33,\n",
       "    \"total_tokens\": 49\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"who composed this tamil song Raamanin mohanam,janaki mandiram , ramayanam, parayanam kadhal mangalam \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58226a83",
   "metadata": {},
   "source": [
    "## Create games using gpt 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551665e",
   "metadata": {},
   "source": [
    "Madlibs:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "184324a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJN6YZNSVEsRHric26r7dYpFL54 at 0x7f8a789e9ea0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n\\nThe teacher_ madlib\\n\\nThe teacher is  very  strict  and  always  yelling  at  us.  We  can't  do  anything  right  in  her  eyes.  She's  always  finding  faults  and  she's  really  mean.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256681,\n",
       "  \"id\": \"cmpl-5NOJN6YZNSVEsRHric26r7dYpFL54\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 68\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create a madlib\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189a753",
   "metadata": {},
   "source": [
    "Mad GAB:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c5d80dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJSMc09YP1bIcOLhRC7Yhuc4xYO at 0x7f8a789e9c20> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\u201d: a game where people try to guess word puzzles. The game is designed to be played out loud, in a group. This \\u201cMad Gab\\u201d game requires at least two people, though more people can play. The object of the game is to guess the phrase that the puzzle describes, based on\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256686,\n",
       "  \"id\": \"cmpl-5NOJSMc09YP1bIcOLhRC7Yhuc4xYO\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 2,\n",
       "    \"total_tokens\": 66\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Mad Gab\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0192b012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJW2VLikXv205DqKCYuDJ2qU7YF at 0x7f8a789e9b30> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nscrabble is a board game in which two to four players score points by placing tiles bearing a single letter onto a board divided into a 15\\u00d715 grid of squares. The tiles must form words that, in crossword fashion, flow left to right in rows or downwards in columns, and be included in\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256690,\n",
       "  \"id\": \"cmpl-5NOJW2VLikXv205DqKCYuDJ2qU7YF\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 68\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"scrabble \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe2deedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJbkCi80ahzO1r5jRfk2IdYZv9l at 0x7f8a680d9b80> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" and aphorisms.\\n\\nTo go a step further, I would say that the aphorism is a specific kind of saying, one that is memorable, pithy, meaningful, and often humorous. An aphorism is a wise saying, or a saying that says a lot in a small space.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256695,\n",
       "  \"id\": \"cmpl-5NOJbkCi80ahzO1r5jRfk2IdYZv9l\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 7,\n",
       "    \"total_tokens\": 71\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"wise or otherwise game of sayings\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d8caa",
   "metadata": {},
   "source": [
    "# opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52141bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJemZhua3WIHMYelShCS6rGTHuO at 0x7f8a680d97c0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"?\\n\\nI think literature is one of the most important things in our lives. It allows us to escape from our everyday lives and experience new and different things. It also helps us to understand the world around us and other people's cultures.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256698,\n",
       "  \"id\": \"cmpl-5NOJemZhua3WIHMYelShCS6rGTHuO\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 56,\n",
       "    \"prompt_tokens\": 6,\n",
       "    \"total_tokens\": 62\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\" what is your opinion on literature\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55dbc740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJhSS2SCi8SIqflbZE45QgaANrm at 0x7f8a680dd900> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nI believe that everyone is entitled to their own opinion. I also believe that everyone has a right to voice their opinion. However, I do not believe that everyone's opinion is valid.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256701,\n",
       "  \"id\": \"cmpl-5NOJhSS2SCi8SIqflbZE45QgaANrm\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 40,\n",
       "    \"prompt_tokens\": 7,\n",
       "    \"total_tokens\": 47\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"what is your opinion on opinions?\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe582519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce0f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac40f091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJj7dD3DPTnA6npS0JQj4YMIf75 at 0x7f8a680754a0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" A: he is a YouTuber\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256703,\n",
       "  \"id\": \"cmpl-5NOJj7dD3DPTnA6npS0JQj4YMIf75\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 59,\n",
       "    \"total_tokens\": 75\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"q:who is bendectict cumber batch A: he is an actor\\nq:who is jhonny depp A: he is an actor\\nq:who is jhonny ive A: he is a designer\\nq:who is casey neistat?\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.8\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bbafa",
   "metadata": {},
   "source": [
    "# Dialogue indentifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33ab3e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJlf8yRG3nGBXhJdYBcYmec6GVO at 0x7f8a680d9f40> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nForrest Gump\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256705,\n",
       "  \"id\": \"cmpl-5NOJlf8yRG3nGBXhJdYBcYmec6GVO\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 21,\n",
       "    \"total_tokens\": 29\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"which movie is this from ....my momma always said that life was like a box of chocolates\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb9ce624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJlV3vElf4Q76EiCMiBBboT2YVj at 0x7f8a680d98b0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThe Godfather\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256705,\n",
       "  \"id\": \"cmpl-5NOJlV3vElf4Q76EiCMiBBboT2YVj\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"total_tokens\": 23\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"which movie is this from ....im gonna make him an offer he cant refuse\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525dcd2b",
   "metadata": {},
   "source": [
    "# MORSE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "581c3f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJmEeUBeFQf9Kv3ezGNXUi338X4 at 0x7f8a68087db0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nSOS\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256706,\n",
       "  \"id\": \"cmpl-5NOJmEeUBeFQf9Kv3ezGNXUi338X4\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 11,\n",
       "    \"total_tokens\": 19\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"convert from morse code to english ...---...\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b44d4dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJnoPFmriDrW7TXGRKkII9ZJ3Ee at 0x7f8a680910e0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" .... .\\n\\nHi there\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256707,\n",
       "  \"id\": \"cmpl-5NOJnoPFmriDrW7TXGRKkII9ZJ3Ee\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 32,\n",
       "    \"total_tokens\": 40\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"convert from morse code to english - .... . ... .... .. .--.  .. ...  ... .. -. -.- .. -. --.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b261ba",
   "metadata": {},
   "source": [
    "## Caeser Cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d544425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJoVWaVSz9DP4UFZsJ6JlZpyJVb at 0x7f8a680e8db0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nThe caeser cipher equivalent of the word hello is ifmmp.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256708,\n",
       "  \"id\": \"cmpl-5NOJoVWaVSz9DP4UFZsJ6JlZpyJVb\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 12,\n",
       "    \"total_tokens\": 36\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"What is the caeser cipher equivalent of the word hello\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ffbced5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOJq237hqlZMHpLuORXrUkWFQVRX at 0x7f8a680e8bd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nTrevor Noah\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256710,\n",
       "  \"id\": \"cmpl-5NOJq237hqlZMHpLuORXrUkWFQVRX\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 8,\n",
       "    \"prompt_tokens\": 105,\n",
       "    \"total_tokens\": 113\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"is this a dave chapelle joke or a trevor noah joke Things like racism are institutionalized. You might not know any bigots. You feel like well I don't hate black people so Im not a racist, but you benefit from racism. Just by the merit, the color of your skin. The opportunities that you have, youre privileged in ways that you might not even realize because you haven't been deprived of certain things. We need to talk about these things in order for them to change. \",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e448839",
   "metadata": {},
   "source": [
    "# Music Notations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"These are the piano notes to what song E – E – F – G – G – F – E – D – C – D – E – E – D – E – E – F – G – G – F – E – D – C – D – E – D – D – E – F – E – D – D – E – F – E – F – E – D – D – G – G – E – E – F – G – G – E – F – E – F – D – D – D – D – E – E – F – E – F – D – E – F – E – F – F – G – E – D – F – E – F – E – F – F – E – F – F – F – F – F – E – F – F – E – F – F – F – F – E – F – F – E – F – F – F – F – E – F – F – E – F.\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b800e",
   "metadata": {},
   "source": [
    "# Movie Recomendation based on previously watched Catergories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b01178",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User likes action,suspence,thriller, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User hates action,witty, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e039d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User likes animals,comedy,pets.... what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"User rom-com,witty, what movie would you recommend\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92f011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os, sys\n",
    "import requests\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from dall_e          import map_pixels, unmap_pixels, load_model\n",
    "from IPython.display import display, display_markdown\n",
    "\n",
    "target_image_size = 256\n",
    "\n",
    "def download_image(url):\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return PIL.Image.open(io.BytesIO(resp.content))\n",
    "\n",
    "def preprocess(img):\n",
    "    s = min(img.size)\n",
    "    \n",
    "    if s < target_image_size:\n",
    "        raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
    "        \n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
    "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return map_pixels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b081eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be changed to a GPU, e.g. 'cuda:0'.\n",
    "dev = torch.device('cpu')\n",
    "\n",
    "# For faster load times, download these files locally and use the local paths instead.\n",
    "enc = load_model(\"https://cdn.openai.com/dall-e/encoder.pkl\", dev)\n",
    "dec = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9770877",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocess(download_image('https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iKIWgaiJUtss/v2/1000x-1.jpg'))\n",
    "display_markdown('Original image:')\n",
    "display(T.ToPILImage(mode='RGB')(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c577f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "z_logits = enc(x)\n",
    "z = torch.argmax(z_logits, axis=1)\n",
    "z = F.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
    "\n",
    "x_stats = dec(z).float()\n",
    "x_rec = unmap_pixels(torch.sigmoid(x_stats[:, :3]))\n",
    "x_rec = T.ToPILImage(mode='RGB')(x_rec[0])\n",
    "\n",
    "display_markdown('Reconstructed image:')\n",
    "display(x_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c5506",
   "metadata": {},
   "source": [
    "# TEXT GRAPHICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf36e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"╭━┳━╭━╭━╮╮/n┃┈┈┈┣▅╋▅┫┃/n┃┈┃┈╰━╰━━━━━━╮/n┳╯┈┈┈┈┈┈┈┈┈◢▉◣/n╲┃┈┈┈┈┈┈┈┈┈▉▉▉/n╲┃┈┈┈┈┈┈┈┈┈◥▉◤/n╲┃┈┈┈┈╭━┳━━━━╯/n╲┣━━━━━━┫/n\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\":‑) :‑( :( \t :‑c :c \t :‑< :<\t:‑[ :[\t:-||\t>:[\t:{\t:@\t:(\t;(\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9cf67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create Emoticons :(\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Create Emoticons :)\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8bc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create ascii that looks like 😀\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "abb8ee33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5LtZgazH2HixujOmlPPROnkZ66RBO at 0x7fe7500692c0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n\\ud83e\\udd23\\ud83e\\udd23\\ud83e\\udd23\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655900200,\n",
       "  \"id\": \"cmpl-5LtZgazH2HixujOmlPPROnkZ66RBO\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 7,\n",
       "    \"total_tokens\": 23\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"create emoticons like 🤣\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffaf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "▒▒▒▒▒▒▐███████▌\n",
    "▒▒▒▒▒▒▐░▀░▀░▀░▌\n",
    "▒▒▒▒▒▒▐▄▄▄▄▄▄▄▌\n",
    "▄▀▀▀█▒▐░▀▀▄▀▀░▌▒█▀▀▀▄\n",
    "▌▌▌▌▐▒▄▌░▄▄▄░▐▄▒▌▐▐▐▐\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ca5d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5LtZXY54dWpALTMXFDwE68O9cSjK5 at 0x7fe750076d60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"  /\\\\_/\\\\\\n ( o.o )\\n  > ^ <\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655900191,\n",
       "  \"id\": \"cmpl-5LtZXY54dWpALTMXFDwE68O9cSjK5\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 24,\n",
       "    \"prompt_tokens\": 213,\n",
       "    \"total_tokens\": 237\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a dog \\n\n",
    "╭━┳━╭━╭━╮╮\n",
    "┃┈┈┈┣▅╋▅┫┃\n",
    "┃┈┃┈╰━╰━━━━━━╮\n",
    "╰┳╯┈┈┈┈┈┈┈┈┈◢▉◣\n",
    "╲┃┈┈┈┈┈┈┈┈┈▉▉▉\n",
    "╲┃┈┈┈┈┈┈┈┈┈◥▉◤\n",
    "╲┃┈┈┈┈╭━┳━━━━╯\n",
    "╲┣━━━━━━┫﻿\n",
    "create an multiline text art dog\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18632820",
   "metadata": {},
   "source": [
    "/\\\\_/\\\\\n",
    "( o.o )\n",
    "> ^ <\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a dog \\n\n",
    "╭━┳━╭━╭━╮╮\n",
    "┃┈┈┈┣▅╋▅┫┃\n",
    "┃┈┃┈╰━╰━━━━━━╮\n",
    "╰┳╯┈┈┈┈┈┈┈┈┈◢▉◣\n",
    "╲┃┈┈┈┈┈┈┈┈┈▉▉▉\n",
    "╲┃┈┈┈┈┈┈┈┈┈◥▉◤\n",
    "╲┃┈┈┈┈╭━┳━━━━╯\n",
    "╲┣━━━━━━┫﻿\n",
    "create an multiline text art dog\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3effce4",
   "metadata": {},
   "source": [
    "/\\\\___/\\\\\\\n",
    "( o   o )\\\n",
    "(  =^=  )\n",
    "(\\\")___(\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4018da5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    " this is a text art sponge bob he is a cartoon character:\n",
    " \n",
    " ▔▔▔▔▔╲\n",
    "▕╮╭┻┻╮╭┻┻╮╭▕╮╲\n",
    "▕╯┃╭╮┃┃╭╮┃╰▕╯╭▏\n",
    "▕╭┻┻┻┛┗┻┻┛ ▕ ╰▏\n",
    "▕╰━━━┓┈┈┈╭╮▕╭╮▏\n",
    "▕╭╮╰┳┳┳┳╯╰╯▕╰╯▏\n",
    "▕╰╯┈┗┛┗┛┈╭╮▕╮┈▏\n",
    "\n",
    "create a text art cartoon character like spongebob\n",
    "\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234e8e6",
   "metadata": {},
   "source": [
    "█▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀▀█\n",
    "█░░╦─╦╔╗╦─╔╗╔╗╔╦╗╔╗░░█\n",
    "█░░"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2a7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a human \\n\n",
    "⠀⠀⠀⠀⢀⣠⠤⡶⣲⢺⣴⣶⢭⣉⢲⣀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⢀⡾⢵⣶⣿⣿⣿⣾⣷⣳⣿⣷⣵⣈⠷⢤⡀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠘⢾⣿⡿⠿⠿⠿⠿⠿⠿⢿⡿⣿⣿⣿⣾⣾⣦⠀⠀⠀⠀\n",
    "⠀⠀⣠⡋⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠻⢿⢿⣧⠀⠀⠀\n",
    "⠀⣰⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣳⢮⣧⠀⠀\n",
    "⢠⣧⠇⡠⠄⣤⣤⣄⡀⠀⠀⣀⣤⣄⣤⣀⠀⠀⣿⣿⣿⣯⣇⠀\n",
    "⠈⣿⠀⢀⣶⣾⣿⣿⠁⠀⢸⣿⣿⣿⣧⣌⣥⠀⠘⣿⣿⣿⣿⠀\n",
    "⢀⣿⠀⠈⠁⠀⠀⠁⠀⠀⠀⠉⠉⠭⠽⠿⠻⠁⠀⣿⣿⣿⡏⠀\n",
    "⡏⠆⠀⠀⠀⠀⠀⠀⡀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠸⠟⢋⣿⣆\n",
    "⡎⠀⠀⢀⡴⠂⠈⠉⠻⠿⠿⠛⣀⢲⣤⣄⣀⠀⠀⠈⠘⣏⢹⡿\n",
    "⠱⡄⠘⢻⣳⣤⡶⠖⠒⠶⠶⢶⣿⣷⣿⣿⣿⣟⠀⠀⠄⠠⣰⠃\n",
    "⠀⢹⠀⠀⠀⠈⠓⠒⠒⠒⠒⠒⠛⠁⢨⣼⣿⣿⡀⣼⠖⠛⠁⠀\n",
    "⠀⠘⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣿⣿⣿⣿⢁⠀⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⢀⣀⣀⣀⣠⣤⣶⣿⣿⣿⡿⣁⡎⢸⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⠘⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠁⠸⠀⠀⠀⠀\n",
    "⠀⠀⢸⠀⠀⠀⠀⠀⢿⣿⣿⣿⣿⣿⡄⠀⡇⠀⠀⠀\n",
    "⠀⢀⣼⠀⠀⠀⠀⠀⠈⢹⣿⣿⣿⡟⣿⣿⣿⣟⡁⠀⢿⣷⡄⠀\n",
    "⠀⣸⣿⠀⠀⠀⠀⠀⠀⠸⣿⣿⣿⣿⣝⣿⣿⡍⠁⠀⢸⣿⣷⠀\n",
    "⠀⣿⣿⡀⠀⠀⠀⠀⠀⢐⣿⣿⣿⣿⣿⣿⣯⠁⠀⠀⢸⣿⣿⠀\n",
    "⠀⢿⢿⣿⣄⠀⠀⠀⠀⢼⣿⣿⣿⣿⣿⣿⡯⠀⢠⢒⣿⣿⡏⠀\n",
    "⠀⠈⢮⡻⣿⣷⣀⠀⢀⢸⣿⣿⣟⣿⣿⠿⠒⣀⣤⣿⣿⠏⠀⠀\n",
    "⠀⠀⠀⠙⠺⣿⣿⣿⣾⣾⣿⣭⣭⣭⣷⣾⣿⣿⣿⠟⠁⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠉⠛⠻⠿⠿⠿⠿⠿⠿⠟⠛⠉⠁⠀⠀⠀\n",
    "create text art \n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676cbd5a",
   "metadata": {},
   "source": [
    "⠀⠀⢀⣠⠤⡶⣲⢺⣴⣶⢭⣉⢲⣀⠀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image of a smile \\n\n",
    "░░░░░░░░░░░░░░░░░░░░█████████░░░░░░░░░\n",
    "░░███████░░░░░░░░░░███▒▒▒▒▒▒▒▒███░░░░░░░\n",
    "░░█▒▒▒▒▒▒█░░░░░░░███▒▒▒▒▒▒▒▒▒▒▒▒▒███░░░░\n",
    "░░░█▒▒▒▒▒▒█░░░░██▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░░\n",
    "░░░░█▒▒▒▒▒█░░░██▒▒▒▒▒██▒▒▒▒▒▒██▒▒▒▒▒███░\n",
    "░░░░░█▒▒▒█░░░█▒▒▒▒▒▒████▒▒▒▒████▒▒▒▒▒▒██\n",
    "░░░█████████████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██\n",
    "░░░█▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒▒▒██\n",
    "░██▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒██▒▒▒▒▒▒▒▒▒▒██▒▒▒▒██\n",
    "██▒▒▒███████████▒▒▒▒▒██▒▒▒▒▒▒▒▒██▒▒▒▒▒██\n",
    "█▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒████████▒▒▒▒▒▒▒██\n",
    "██▒▒▒▒▒▒▒▒▒▒▒▒▒▒█▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░\n",
    "░█▒▒▒███████████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒██░░░\n",
    "░██▒▒▒▒▒▒▒▒▒▒████▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒█░░░░░\n",
    "░░████████████░░░█████████████████░░░░░░\n",
    "\n",
    "create text art smile\n",
    "  \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84716b",
   "metadata": {},
   "source": [
    "░░░░░░░░░░░░░░░░░░░░█████████░░░░░░░░░\n",
    "░░███████░░░░░░░░░░███▒▒▒▒▒▒▒▒███░░░░░░░\n",
    "░░█▒▒▒▒▒▒█░░░░░░░███▒▒▒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a563dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "this is a text art image \n",
    " /﹋\\\n",
    "(҂`_´)\n",
    "<,︻╦╤─ ҉ - -\n",
    "/﹋\\\n",
    "  \n",
    "create a text art image \n",
    "\"\"\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11ec9a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOPQExQCQeihSzaP1OmpzwwQAHlV at 0x7f8a680fac20> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\nThe easiest BMTc Volvo bus to take from JP Nagar to Tattatsu Idea Labs is the BMTC Volvo Bus Route number 500.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656257056,\n",
       "  \"id\": \"cmpl-5NOPQExQCQeihSzaP1OmpzwwQAHlV\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 32,\n",
       "    \"prompt_tokens\": 28,\n",
       "    \"total_tokens\": 60\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what is the easiest bmtc volvo bus to take from jp nagar to tattatsu idea labs\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da047c4",
   "metadata": {},
   "source": [
    "# HIEROGLYPHYICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    egyptian hierogliphics\n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e44f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what is \\n  \\ud80c\\udc80\\ud80c\\udd53\\ud80c\\udfcf\\ud80c\\udff2\\ud80c\\ude96\\ud80c\\udfcf\\ud80c\\udfcf in english\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d0c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    write the house of the horizon in hieroglyphics\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d51c9",
   "metadata": {},
   "source": [
    "# 𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "    what does this scentence written in hierorogliphics 𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍 mean\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "072ecbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5LtZPoQMBx8FHog28DgVrNW4oniCd at 0x7fe7b0c0ac70> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\n\\ud80c\\udc8b\\ud80c\\udfcf\\ud80c\\uddf3\\ud80c\\udd53\\ud80c\\udc8b\\ud80c\\ude16\\ud80c\\udd71\\ud80c\\ude96\\ud80c\\udfcf\\ud80c\\ude16\\ud80c\\udda4\\ud80c\\udd53\\ud80c\\udc8b\\ud80c\\ude96\\ud80c\\ude3e\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655900183,\n",
       "  \"id\": \"cmpl-5LtZPoQMBx8FHog28DgVrNW4oniCd\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 64,\n",
       "    \"prompt_tokens\": 19,\n",
       "    \"total_tokens\": 83\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "   write i am an egyptian god in hierogliphics\n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"\"\"\n",
    "\n",
    "     𓀀𓂋𓆤𓈖𓈙𓈸𓉐𓉘𓊼𓋴𓌆𓍢𓎼𓏭𓐍 \n",
    "    \n",
    "    \"\"\",\n",
    "  \n",
    "  temperature=0.7,\n",
    "  max_tokens=64,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    "    \n",
    ")\n",
    "response\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce970c7",
   "metadata": {},
   "source": [
    "# 𓐎𓐏𓐐𓐑𓐒𓐓𓐔𓐕𓐖𓐗𓐘𓐙𓐚𓐛𓐜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57cc9ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOMwjri1upLJDgDtZrZ1sDTaEiw8 at 0x7f8a680e8590> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656256902,\n",
       "  \"id\": \"cmpl-5NOMwjri1upLJDgDtZrZ1sDTaEiw8\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 8,\n",
       "    \"total_tokens\": 9\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"How good is pizzahut pizza?\",\n",
    "  temperature=0,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "045398e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5LtZIJMCyHbFMVHbJQVePAb9Bc5xt at 0x7fe7b0c0a720> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1655900176,\n",
       "  \"id\": \"cmpl-5LtZIJMCyHbFMVHbJQVePAb9Bc5xt\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"total_tokens\": 14\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"What is the best way to get from point a to point b\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6648376e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-5NOPBLYj2ZughIzmFSy5Ae1rRvCU4 at 0x7f8a680fa5e0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1656257041,\n",
       "  \"id\": \"cmpl-5NOPBLYj2ZughIzmFSy5Ae1rRvCU4\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 20,\n",
       "    \"total_tokens\": 21\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"What is the best bmtc bus to get from tataatsu idealabs to metro station?\",\n",
    "  temperature=0.7,\n",
    "  max_tokens=1,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    "  stop=[\"\\n\"]\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897addd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda36cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c305a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1deadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f4acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1f987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
